name: Benchmark build
on:
  workflow_dispatch:
  pull_request:
    branches: [ master ]
    types: [opened, labeled, unlabeled, synchronize]
  push:
    branches:
      - 'master'
    tags:
      - 'v*'

jobs:
  haslabel:
    name: analyse labels
    runs-on: ubuntu-latest
    outputs:
      has-benchmark-label: ${{ steps.haslabel.outputs.labeled-run-benchmark }}
    steps:
      - name: Labeled with run-benchmark
        id: haslabel
        uses: FalkorDB/HasLabel@v1.0.5
        with:
          contains: 'run-benchmark'
      - name: Print head ref
        run: echo ${{ fromJson(github.head_ref) }}

#  create-runners:
#    needs: haslabel
#    if: ${{ needs.haslabel.outputs.has-benchmark-label || github.event_name != 'pull_request' }}
#    strategy:
#      matrix:
#        benchmark_group: [A, B]
#    runs-on: ubuntu-latest
#    steps:
#      - name: Create Runner For Benchmarak
#        id: create-runner
#        uses: FalkorDB/gce-github-runner@install_docker
#        with:
#          token: ${{ secrets.GH_SA_TOKEN }}
#          project_id: github-runners-414914
#          service_account_key: ${{ secrets.GCP_SA_KEY }}
#          machine_zone: us-central1-a
#          machine_type: n4-highcpu-8
#          network: gh-runner
#          runner_label: ${GITHUB_RUN_ID}-${GITHUB_RUN_NUMBER}-${{ matrix.benchmark_group }}
#
#  run-benchmarks:
#    needs:
#      - create-runners
#    strategy:
#      matrix:
#        benchmark_group: [ A, B ]
#    runs-on: ${{ github.run_id }}-${{ github.run_number }}-${{ matrix.benchmark_group }}
#    container: falkordb/falkordb-build:ubuntu
#    outputs:
#      ref_name: ${{ steps.set-ref-name.outputs.ref_name }}
#    steps:
#      - name: Safe dir
#        run: git config --global --add safe.directory '*'
#
#      - uses: actions/checkout@v4
#        with:
#          set-safe-directory: '*'
#          submodules: recursive
#
#      - name: Cache GraphBLAS
#        id: cache_graphblas
#        uses: actions/cache@v4
#        with:
#          path: ./bin/linux-x64-release/GraphBLAS
#          key: graphblas-x64-${{ hashFiles('./deps/GraphBLAS/Include/GraphBLAS.h') }}
#
#      - name: Cache parser
#        id: cache_parser
#        uses: actions/cache@v4
#        with:
#          path: ./bin/linux-x64-release/libcypher-parser
#          key: parser-x64-${{ hashFiles('./deps/libcypher-parser/lib/src/parser.c') }}
#
#      - name: Cache search
#        id: cache_search
#        uses: actions/cache@v4
#        with:
#          path: ./bin/linux-x64-release/search-static
#          key: search-x64-${{ hashFiles('./deps/RediSearch/src/version.h') }}
#
#      - name: Build
#        run: |
#          rustup toolchain list
#          rustup default nightly
#          apt-get update
#          apt-get install -y clang libomp-dev libc6-dbg python3-venv python3-pip lsb-release
#          curl -fsSL https://packages.redis.io/gpg | gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg && \
#          echo "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main" | tee /etc/apt/sources.list.d/redis.list
#          apt update && apt install -y redis
#          make $(j16)
#        continue-on-error: true
#
#      - name: Install benchmark dependencies
#        working-directory: tests/benchmarks
#        run: |
#          python3 -m venv venv
#          . venv/bin/activate
#          pip install -r benchmarks_requirements.txt
#
#      - name: Run benchmark
#        working-directory: tests/benchmarks
#        run: |
#          . venv/bin/activate
#          python3 run_benchmarks.py Group${{ matrix.benchmark_group }}
#
#      - name: Set ref name
#        id: set-ref-name
#        run: |
#          if {{ github.event_name == 'pull_request' }}; then
#            echo "ref_name=pr-${{ github.head_ref }}" >> $GITHUB_OUTPUT
#          else
#            echo "ref_name=${{ github.ref_name }}" >> $GITHUB_OUTPUT
#          fi
#
#      - name: Upload results
#        uses: actions/upload-artifact@v4
#        with:
#          name: ${{ steps.set-ref-name.outputs.ref_name }}-benchmark-Group${{ matrix.benchmark_group }}-results
#          path: tests/benchmarks/*-results.json
#          retention-days: 1
#
#  merge-results:
#    needs:
#      - run-benchmarks
#    runs-on: ubuntu-latest
#    outputs:
#        ref_name: ${{ needs.run-benchmarks.outputs.ref_name }}
#    steps:
#      - uses: actions/checkout@v4
#      - name: Download artifact A
#        uses: actions/download-artifact@v4
#        with:
#          name: ${{ needs.run-benchmarks.outputs.ref_name }}-benchmark-GroupA-results
#      - name: Download artifact B
#        uses: actions/download-artifact@v4
#        with:
#          name: ${{ needs.run-benchmarks.outputs.ref_name }}-benchmark-GroupB-results
#      - name: Merge results
#        run: |
#          unzip ${{ needs.run-benchmarks.outputs.ref_name }}-benchmark-GroupA-results.zip
#          unzip ${{ needs.run-benchmarks.outputs.ref_name }}-benchmark-GroupB-results.zip
#      - name: Upload merged results
#        uses: actions/upload-artifact@v4
#        with:
#          name: ${{ needs.run-benchmarks.outputs.ref_name }}-benchmark-results
#          path: ./*-results.json
#
#  use-artifacts:
#    needs:
#      - merge-results
#    if: ${{ github.event_name == 'pull_request' }} # No need to run this job for branches and tags
#    runs-on: ubuntu-latest
#    steps:
#      - uses: actions/checkout@v4
#      - name: Download artifact
#        uses: actions/download-artifact@v4
#        with:
#          name: ${{ needs.merge-results.outputs.ref_name }}-benchmark-results
#          path: $GITHUB_WORKSPACE/tests/benchmarks
#
#      - name: Download master artifact
#        uses: actions/download-artifact@v4
#        with:
#          name: ${{ needs.merge-results.outputs.ref_name }}-benchmark-results
#          path: $GITHUB_WORKSPACE/tests/benchmarks
#
#      - name: Merge results
#        working-directory: tests/benchmarks
#        run: |
#          unzip ${{ needs.merge-results.outputs.ref_name }}-benchmark-results.zip -d compare/${{ needs.merge-results.outputs.ref_name }}
#          unzip ${{ needs.merge-results.outputs.ref_name }}-benchmark-results.zip -d compare/master
##          unzip master-benchmark-results.zip -d compare/master
#
#      - name: Install dependencies
#        working-directory: tests/benchmarks
#        run: |
#          python3 -m venv venv
#          . venv/bin/activate
#          pip install -r comparison_requirements.txt
#
#      - name: Generate markdown
#        working-directory: tests/benchmarks
#        run: |
#          . venv/bin/activate
#          python3 generate_markdown.py
#
#      - name: Comment on Pull Request
#        uses: actions/github-script@v7
#        with:
#          github-token: ${{ secrets.GITHUB_TOKEN }}
#          script: |
#            const fs = require('fs');
#            const markdown = await fs.readFile('tests/benchmarks/compare.md', 'utf8');
#            const pullRequest = context.payload.pull_request
#            await github.pulls.createReview({
#              owner: context.repo.owner,
#              repo: context.repo.repo,
#              pull_number: pullRequest.number,
#              body: markdown,
#              event: 'COMMENT'
#            });
